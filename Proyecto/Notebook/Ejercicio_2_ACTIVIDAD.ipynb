{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wicked-pavilion",
   "metadata": {},
   "source": [
    "# ACTIVIDAD #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-photography",
   "metadata": {},
   "source": [
    "##  Construye un detector de movimiento en una región de interés de la imagen marcada manualmente. Guarda 2 ó 3 segundos de la secuencia detectada en un archivo de vídeo. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-smith",
   "metadata": {},
   "source": [
    "La sucesión de pasos para aplicar una Región de interés en una imagen (ROI) es: crear un ROI en la imagen, realizar la operación que desea en esta subregión de la imagen, restablecer el ROI.\n",
    "\n",
    "En este notebook veremos como aplicar un ROI siguiendo un esquema diferente al utilizado por el profesor ya que se basa en en la aplicación de trackers de objetos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a506f21f",
   "metadata": {},
   "source": [
    "Object Tracking es un mecanismo muy extendido en OpenCV que consiste en determinar una zona donde existe un objeto y frame a frame se estudia su posición.\n",
    "\n",
    "Existen varios mecanismos de tracking[1](https://www.pyimagesearch.com/2018/07/30/opencv-object-tracking/). De los cuales es ha seleccionado uno solo, en concreto se utilizará DCF (Discriminative Correlation Filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c0b4c1",
   "metadata": {},
   "source": [
    "### DCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19af30",
   "metadata": {},
   "source": [
    "Los DCF obtienen muy buen rendimiengo en seguimiento a corto plazo. El mapa de confiabilidad espacial ajusta el soporte del filtro a la parte del objeto adecuada para el seguimiento. Esto permite ampliar la región de búsqueda y mejora el seguimiento de objetos no rectangulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74966381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos tracker Discriminative Correlation Filter\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "\n",
    "(...)\n",
    "\n",
    "# Iniciamos el tracker sobre el objeto\n",
    "success = tracker.init(frame, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8714e6",
   "metadata": {},
   "source": [
    "## Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc1b21",
   "metadata": {},
   "source": [
    "El diseño se basa en la implementación del seguimiento de objetos[2](https://learnopencv.com/object-tracking-using-opencv-cpp-python/) que es más rápida que la detección de objetos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6783b",
   "metadata": {},
   "source": [
    "Una vez establecido un algoritmo de seguimiento se ha implementado la lógica de la región de interés (ROI). Para adecuarlo al sistema que utiliza el algoritmo (ya que no está incluido en el paquete umucv) se ha utilizado la generación del ROI con OpenCV. \n",
    "\n",
    "Se utiliza el primer frame de video para obtener un punto de selección del objeto, a continuación se deberá presionar `Enter` para finalizar la selección.\n",
    "\n",
    "Llegados a este punto comienza a reproducirse el vídeo tomado por la cámara que nos permite ver en tiempo real la posición del objeto. La caja se redibuja en el objeto a cada frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si tenemos trakeado el objeto\n",
    "    if success:\n",
    "        # Creamos la caja\n",
    "        p1 = (int(bbox[0]), int(bbox[1]))\n",
    "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "        cv.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1cdc4",
   "metadata": {},
   "source": [
    "Para concluir se ha implementado la funcionalidad de grabar, que permite, pulsando la tecla `G` grabar una fracción de tiempo hasta que se pulse de nuevo `G`. La tecla de `ESC` permite finalizar el programa (y la grabación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if grabar:\n",
    "        capture.write(frame)\n",
    "    cv.imshow(\"Tracking\", frame)\n",
    "    k = cv.waitKey(1) & 0xff\n",
    "    if k == ord('g'):\n",
    "        grabar = not grabar\n",
    "    elif k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501cdd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video alt=\"test\" idth=\"320\" height=\"240\"  controls>\n",
       "        <source src=\"../Images/2_ACTIVIDAD/ACTIVIDAD1.mp4\" type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video alt=\"test\" idth=\"320\" height=\"240\"  controls>\n",
    "        <source src=\"../Images/2_ACTIVIDAD/ACTIVIDAD1.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-joshua",
   "metadata": {},
   "source": [
    "##  Opcional: muestra el objeto seleccionado anulando el fondo. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a3f71",
   "metadata": {},
   "source": [
    "Para este ejercicio me he basado en las ideas aportadas en el notebook `chroma`, concretamente en la sección final donde se comenta los métodos para modelar y eliminar el fondo de una imagen[3](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_video/py_bg_subtraction/py_bg_subtraction.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d130ad7",
   "metadata": {},
   "source": [
    "La idea es utilizar un subtractor que consiste en un algoritmo de detección de fondo. Cuando una imagen se estabilza el contenido que no se mueve en varios frames se considera fondo. Esto genera unos píxeles activos y otros inactivos. La idea de diseño consiste en obtener esos pixeles y aplicarlos sobre los frames como una máscara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188dfed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg = cv.createBackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aefdc2a",
   "metadata": {},
   "source": [
    "MOG2 es un algoritmo de segmentación de fondo / primer plano basado en mezclas gaussianas. Una característica importante de este algoritmo es que selecciona el número apropiado de distribución gaussiana para cada píxel.\n",
    "\n",
    "MOG2 tiene la opción de seleccionar si se detectará la sombra o no. Si `detectShadows = True` (que es así por defecto), detecta y marca las sombras, pero reduce la velocidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e40c106",
   "metadata": {},
   "source": [
    "A continuación vamos a aplicaremos un filtro de imagen para eliminar pequeños puntos activos de ruido. Luego utilizaremos el resultado como una máscara y la aplicaremos a la imagen principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7325841",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgmask = fgbg.apply(frame)\n",
    "fgmask = cv.morphologyEx(fgmask, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "bg = cv.bitwise_and(frame, frame, mask=fgmask)\n",
    "final = cv.bitwise_or(bg, cv.resize(background, (1280, 720)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f7248",
   "metadata": {},
   "source": [
    "El resultado puede verse en dos ventanas. En una se muestra la aplicación del algoritmo MOG2 y en otra el resultado. Cabe destacar que cuando el objeto queda parado se comienza a convertir en fondo por lo que es eliminado por el filtro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577769ca",
   "metadata": {},
   "source": [
    "<div> <img src=\"../Images/2_ACTIVIDAD/f2.png\" width=\"300\"/> </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594a0e93",
   "metadata": {},
   "source": [
    "<div> <img src=\"../Images/2_ACTIVIDAD/f1.png\" width=\"300\"/> </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9fff5",
   "metadata": {},
   "source": [
    "## Resultado final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0630af",
   "metadata": {},
   "source": [
    "En estos dos videos se muestra el resultado en tiempo real de mover un objeto. El fondo es eliminado y en su lugar podría ponerse una imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc00fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video alt=\"test\" idth=\"320\" height=\"240\"  controls>\n",
       "        <source src=\"../Images/2_ACTIVIDAD/ACTIVIDAD2.mp4\" type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video alt=\"test\" idth=\"320\" height=\"240\"  controls>\n",
    "        <source src=\"../Images/2_ACTIVIDAD/ACTIVIDAD2.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dbccc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video alt=\"test\" idth=\"320\" height=\"240\"  controls>\n",
       "        <source src=\"../Images/2_ACTIVIDAD/ACTIVIDAD3.mp4\" type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video alt=\"test\" idth=\"320\" height=\"240\"  controls>\n",
    "        <source src=\"../Images/2_ACTIVIDAD/ACTIVIDAD3.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
